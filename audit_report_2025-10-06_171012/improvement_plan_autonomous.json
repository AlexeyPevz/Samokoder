{
  "meta": {
    "version": "3.0",
    "date": "2025-10-06",
    "methodology": "Autonomous deep code audit + existing improvement_plan.json analysis",
    "total_improvements": 18,
    "total_effort_days": 23.0,
    "priorities": {
      "P0_critical_blockers": 2,
      "P1_high_priority": 6,
      "P2_medium_priority": 5,
      "P3_low_priority": 3,
      "P4_backlog": 2
    }
  },
  "improvements": [
    {
      "id": "CR-1",
      "title": "Fix Missing Rollback в Orchestrator Exit Path",
      "priority": "P0",
      "severity": "critical",
      "category": "data_integrity",
      "problem": {
        "description": "При выходе из Orchestrator.run() изменения в next_state могут быть случайно committed без rollback",
        "file": "core/agents/orchestrator.py",
        "lines": [118],
        "code_snippet": "# TODO: rollback changes to \"next\" so they aren't accidentally committed?\nreturn True",
        "evidence": "Explicit TODO в критичном месте exit path"
      },
      "impact": {
        "risk": "Data corruption при unexpected exit (Ctrl+C, exception)",
        "affected_users": "All users (любой project generation)",
        "frequency": "Low (только при abnormal exit)",
        "severity_score": 9
      },
      "change": {
        "description": "Добавить rollback перед return в exit path",
        "implementation": "if self.next_state and self.next_state != self.current_state:\n    await self.state_manager.rollback()\nreturn True",
        "tests": "test_orchestrator_rollback_on_exit(), test_orchestrator_rollback_on_exception()",
        "breaking_changes": false
      },
      "effect": {
        "kpis": {
          "data_integrity": "+100%",
          "bug_risk": "-80%"
        },
        "measured": false
      },
      "effort_days": 0.5,
      "dependencies": [],
      "source": "improvement_plan.json:16-63, code review"
    },
    {
      "id": "CR-2",
      "title": "Enforce MAX_CODING_ATTEMPTS Limit (Prevent Infinite Loop)",
      "priority": "P0",
      "severity": "critical",
      "category": "reliability",
      "problem": {
        "description": "Потенциальный бесконечный цикл если LLM генерирует invalid код; MAX_CODING_ATTEMPTS определён но не enforced",
        "file": "core/agents/code_monkey.py",
        "lines": [129],
        "code_snippet": "# FIXME: provide a counter here so that we don't have an endless loop here",
        "evidence": "Explicit FIXME, attempt counter не checked"
      },
      "impact": {
        "risk": "Worker hang, blocked queue, wasted LLM tokens",
        "affected_users": "All users (worker hang blocks all)",
        "frequency": "Low-Medium (depends on LLM errors)",
        "severity_score": 8
      },
      "change": {
        "description": "Enforce MAX_CODING_ATTEMPTS limit с graceful degradation",
        "implementation": "if attempt >= MAX_CODING_ATTEMPTS:\n    log.warning(f\"Max attempts reached ({MAX_CODING_ATTEMPTS})\")\n    return {\"new_content\": response or file_content, \"attempt\": attempt}",
        "tests": "test_code_monkey_max_attempts_reached()",
        "breaking_changes": false
      },
      "effect": {
        "kpis": {
          "worker_availability": "+100%",
          "llm_cost_waste": "-90%",
          "mttr": "-60min"
        },
        "measured": false
      },
      "effort_days": 0.5,
      "dependencies": [],
      "source": "improvement_plan.json:64-111, code review"
    },
    {
      "id": "DB-1",
      "title": "Add Critical Database Indexes (Performance)",
      "priority": "P1",
      "severity": "high",
      "category": "performance",
      "status": "completed_v1.0.1",
      "problem": {
        "description": "Missing indexes для частых queries (projects.user_id, llm_requests.project_id, etc.)",
        "file": "alembic/versions/20251006_add_performance_indexes.py",
        "evidence": "Migration already created в v1.0.1"
      },
      "impact": {
        "improvement": "Query time -90% (500ms → 50ms)",
        "severity_score": 7
      },
      "effect": {
        "kpis": {
          "query_time": "-90%",
          "db_load": "-60%",
          "user_perceived_latency": "-70%"
        },
        "measured": true
      },
      "effort_days": 1.0,
      "completed_date": "2025-10-06",
      "source": "CHANGELOG.md:34-35, improvement_plan.json:159-202"
    },
    {
      "id": "CR-3",
      "title": "Normalize ProjectState (Remove JSONB Bloat)",
      "priority": "P1",
      "severity": "high",
      "category": "scalability",
      "problem": {
        "description": "ProjectState.data JSONB хранит весь state (epics, tasks, steps, iterations); размер 50-150 KB per row",
        "file": "core/db/models/project_state.py",
        "lines": [67, 68, 69, 70],
        "code_snippet": "epics: Mapped[list[dict]]\ntasks: Mapped[list[dict]]  # 200+ tasks\nsteps: Mapped[list[dict]]  # 100+ steps\niterations: Mapped[list[dict]]",
        "evidence": "DB size projection: 5 GB для 50k projects"
      },
      "impact": {
        "risk": "Scalability bottleneck, slow queries, DB cost",
        "affected_users": "All users (всем проектам)",
        "frequency": "Always (каждый DB query)",
        "severity_score": 8
      },
      "change": {
        "description": "Создать separate tables: Epic, Task, Step, Iteration с FK к ProjectState",
        "implementation": "1) Create normalized models; 2) Alembic migrations; 3) Data migration; 4) Update queries",
        "tests": "test_normalized_queries(), test_data_migration_zero_loss()",
        "breaking_changes": true
      },
      "effect": {
        "kpis": {
          "db_size": "-70% (5 GB → 1.5 GB)",
          "query_time": "-80% (O(n) → O(1))",
          "scalability_ceiling": "+10x (10k → 100k projects)"
        },
        "measured": false
      },
      "effort_days": 5.0,
      "dependencies": ["DB-1"],
      "source": "improvement_plan.json:203-254, docs/architecture.md:826-829"
    },
    {
      "id": "INFRA-1",
      "title": "Terraform для Yandex Cloud Infrastructure",
      "priority": "P1",
      "severity": "high",
      "category": "infrastructure",
      "problem": {
        "description": "Manual deployment на Yandex Cloud; нет IaC (Infrastructure as Code)",
        "file": "deploy_yc.sh",
        "evidence": "Отсутствие Terraform файлов, manual script"
      },
      "impact": {
        "risk": "Human error, slow deployments, no reproducibility",
        "deployment_time_current": "30 minutes",
        "error_rate_current": "High",
        "severity_score": 7
      },
      "change": {
        "description": "Создать Terraform configuration для Yandex Cloud (VPC, VM, DB, Redis, ALB)",
        "implementation": "main.tf для infrastructure provisioning",
        "tests": "terraform plan, terraform apply на test account",
        "breaking_changes": false
      },
      "effect": {
        "kpis": {
          "deployment_time": "-60% (30min → 12min)",
          "error_rate": "-80%",
          "reproducibility": "+100%"
        },
        "measured": false
      },
      "effort_days": 3.0,
      "dependencies": [],
      "source": "improvement_plan.json:669-711"
    },
    {
      "id": "H-2",
      "title": "Add Tests для parallel.py (Critical Optimization)",
      "priority": "P1",
      "severity": "high",
      "category": "testing",
      "problem": {
        "description": "parallel.py (158 LOC) — критичная оптимизация (5x-15x speedup), но 0 test coverage",
        "file": "tests/llm/test_parallel.py",
        "evidence": "File не существует, grep shows 0 coverage"
      },
      "impact": {
        "risk": "Regression в critical optimization, no safety net для refactoring",
        "severity_score": 7
      },
      "change": {
        "description": "Написать comprehensive tests для parallel LLM execution",
        "implementation": "test_gather_llm_requests(), test_semaphore_limiting(), test_timeout(), test_exceptions()",
        "tests": "5+ test cases",
        "breaking_changes": false
      },
      "effect": {
        "kpis": {
          "test_coverage": "+158 LOC",
          "regression_risk": "-80%",
          "refactoring_confidence": "+90%"
        },
        "measured": true
      },
      "effort_days": 1.0,
      "dependencies": [],
      "source": "improvement_plan.json:256-304"
    },
    {
      "id": "H-3",
      "title": "Remove Duplicate model_choices.py (Code Quality)",
      "priority": "P1",
      "severity": "high",
      "category": "code_quality",
      "problem": {
        "description": "Дубликация model_choices.py (200 LOC) в api/models/ и core/config/",
        "file": "api/models/model_choices.py, core/config/model_choices.py",
        "evidence": "diff показал 100% overlap"
      },
      "impact": {
        "risk": "Sync проблемы, maintainability",
        "severity_score": 6
      },
      "change": {
        "description": "Оставить одну копию в core/config/, удалить из api/models/",
        "implementation": "Update imports → delete duplicate",
        "tests": "test_model_choices_import()",
        "breaking_changes": false
      },
      "effect": {
        "kpis": {
          "code_duplication": "-200 LOC",
          "maintainability": "+50%"
        },
        "measured": true
      },
      "effort_days": 1.0,
      "dependencies": [],
      "source": "improvement_plan.json:115-156"
    },
    {
      "id": "SCALE-1",
      "title": "Multiple ARQ Worker Instances (Horizontal Scaling)",
      "priority": "P1",
      "severity": "high",
      "category": "scalability",
      "problem": {
        "description": "Single worker instance — bottleneck для concurrent project generation",
        "file": "worker/main.py",
        "evidence": "Single WorkerSettings, docker-compose.yml has 1 worker"
      },
      "impact": {
        "bottleneck_at": "10 concurrent projects",
        "severity_score": 8
      },
      "change": {
        "description": "Scale worker instances horizontally (ARQ supports это natively)",
        "implementation": "docker-compose scale worker=5",
        "tests": "test_concurrent_project_generation()",
        "breaking_changes": false
      },
      "effect": {
        "kpis": {
          "concurrent_capacity": "+5x (10 → 50 projects)",
          "queue_latency": "-80%"
        },
        "measured": false
      },
      "effort_days": 0.5,
      "dependencies": [],
      "source": "docs/architecture.md:656, code review"
    },
    {
      "id": "SEC-001",
      "title": "Docker Socket Security Phase 2 (Sysbox Runtime)",
      "priority": "P2",
      "severity": "high",
      "category": "security",
      "problem": {
        "description": "Docker socket access (even read-only) allows container exec → partial RCE risk",
        "file": "docker-compose.yml",
        "lines": [39, 92],
        "current_cvss": 7.5,
        "evidence": "Read-only socket mount (Phase 1 done), but exec still possible"
      },
      "impact": {
        "risk": "Container escape → RCE → host compromise",
        "severity_score": 7
      },
      "change": {
        "description": "Implement Sysbox runtime (rootless containers) or Kubernetes + gVisor",
        "implementation": "Install Sysbox → update docker-compose → test isolation",
        "tests": "Security penetration testing",
        "breaking_changes": false
      },
      "effect": {
        "kpis": {
          "cvss_score": "7.5 → 4.0 (-46%)",
          "container_escape_risk": "-90%"
        },
        "measured": false
      },
      "effort_days": 5.0,
      "dependencies": [],
      "source": "docs/adr/004-security-hardening-docker-isolation.md"
    },
    {
      "id": "SEC-002",
      "title": "LLM Prompt Sanitization (Injection Prevention)",
      "priority": "P2",
      "severity": "medium",
      "category": "security",
      "problem": {
        "description": "User prompts не sanitized → malicious prompts могут генерировать harmful code",
        "file": "core/agents/spec_writer.py",
        "evidence": "No input validation перед LLM call"
      },
      "impact": {
        "risk": "LLM prompt injection → malicious code generation",
        "severity_score": 6
      },
      "change": {
        "description": "Add prompt validation, LLM guardrails, output validation",
        "implementation": "Integrate Llama Guard or Azure Content Safety",
        "tests": "test_prompt_injection_blocked()",
        "breaking_changes": false
      },
      "effect": {
        "kpis": {
          "prompt_injection_risk": "-80%"
        },
        "measured": false
      },
      "effort_days": 3.0,
      "dependencies": [],
      "source": "Code review inference"
    },
    {
      "id": "H-1",
      "title": "Refactor Orchestrator.create_agent() God Method",
      "priority": "P2",
      "severity": "medium",
      "category": "maintainability",
      "problem": {
        "description": "create_agent() method — 111 LOC, cyclomatic complexity ~20",
        "file": "core/agents/orchestrator.py",
        "lines": [243, 354],
        "evidence": "Complexity metrics, hard to test/maintain"
      },
      "impact": {
        "risk": "High maintenance burden, regression risk",
        "severity_score": 5
      },
      "change": {
        "description": "Apply Strategy Pattern or Routing Table",
        "implementation": "AgentFactory с routing table",
        "tests": "test_agent_factory_routing()",
        "breaking_changes": false
      },
      "effect": {
        "kpis": {
          "cyclomatic_complexity": "-50% (20 → 10)",
          "test_coverage": "+20%",
          "time_to_add_new_agent": "-40%"
        },
        "measured": false
      },
      "effort_days": 2.0,
      "dependencies": [],
      "source": "improvement_plan.json:305-351"
    },
    {
      "id": "REL-003",
      "title": "Optimistic Locking для ProjectState",
      "priority": "P2",
      "severity": "medium",
      "category": "reliability",
      "problem": {
        "description": "Concurrent updates могут перезаписать друг друга (last writer wins)",
        "file": "core/db/models/project_state.py",
        "evidence": "No version column, no conflict detection"
      },
      "impact": {
        "risk": "Data loss при concurrent agent execution",
        "severity_score": 6
      },
      "change": {
        "description": "Add version column + optimistic locking check",
        "implementation": "version: int, check на update",
        "tests": "test_concurrent_update_conflict()",
        "breaking_changes": true
      },
      "effect": {
        "kpis": {
          "data_loss_risk": "-95%"
        },
        "measured": false
      },
      "effort_days": 2.0,
      "dependencies": [],
      "source": "docs/architecture.md:596-600"
    },
    {
      "id": "CACHE-1",
      "title": "Redis Caching Layer (Performance)",
      "priority": "P2",
      "severity": "medium",
      "category": "performance",
      "problem": {
        "description": "Redis используется минимально (только rate limiting + queue); no caching",
        "file": "core/db/session.py",
        "evidence": "No cache decorators, повторные DB queries"
      },
      "impact": {
        "unnecessary_db_load": "Высокий (повторные queries)",
        "severity_score": 5
      },
      "change": {
        "description": "Cache project metadata, LLM responses (idempotent)",
        "implementation": "Redis cache decorator, TTL 5-15 min",
        "tests": "test_cache_hit_rate()",
        "breaking_changes": false
      },
      "effect": {
        "kpis": {
          "db_load": "-40%",
          "api_latency": "-20%"
        },
        "measured": false
      },
      "effort_days": 2.0,
      "dependencies": [],
      "source": "docs/architecture.md:836-839"
    },
    {
      "id": "OBS-1",
      "title": "Distributed Tracing (Observability)",
      "priority": "P2",
      "severity": "medium",
      "category": "observability",
      "problem": {
        "description": "No distributed tracing (Jaeger/Tempo), no correlation IDs",
        "file": "N/A",
        "evidence": "Нет трейсинга в коде"
      },
      "impact": {
        "debugging_difficulty": "High (complex multi-agent workflows)",
        "severity_score": 5
      },
      "change": {
        "description": "Integrate OpenTelemetry + Tempo/Jaeger",
        "implementation": "Add tracing spans, correlation IDs",
        "tests": "test_trace_propagation()",
        "breaking_changes": false
      },
      "effect": {
        "kpis": {
          "mttr": "-50%",
          "debugging_efficiency": "+80%"
        },
        "measured": false
      },
      "effort_days": 5.0,
      "dependencies": [],
      "source": "docs/architecture.md:706-712"
    },
    {
      "id": "M-1",
      "title": "Replace Busy-Wait Lock с asyncio.Lock",
      "priority": "P3",
      "severity": "low",
      "category": "code_quality",
      "problem": {
        "description": "StateManager.db_blocker() использует busy-wait (sleep 0.1s)",
        "file": "core/state/state_manager.py",
        "lines": [435, 443],
        "evidence": "while self.blockDb: await asyncio.sleep(0.1)"
      },
      "impact": {
        "cpu_waste": "Low (но code smell)",
        "severity_score": 3
      },
      "change": {
        "description": "Replace с asyncio.Lock()",
        "implementation": "self._db_lock = Lock(); async with self._db_lock: yield",
        "tests": "test_db_lock_concurrency()",
        "breaking_changes": false
      },
      "effect": {
        "kpis": {
          "cpu_usage": "-5%",
          "code_quality": "+10%"
        },
        "measured": false
      },
      "effort_days": 0.5,
      "dependencies": [],
      "source": "improvement_plan.json:354-397"
    },
    {
      "id": "M-4",
      "title": "Config-Driven Agent Limits",
      "priority": "P3",
      "severity": "low",
      "category": "configuration",
      "problem": {
        "description": "Hardcoded MAX_REVIEW_RETRIES=2, MAX_CODING_ATTEMPTS=3",
        "file": "core/agents/code_monkey.py",
        "lines": [26, 29],
        "evidence": "Magic numbers, нельзя настроить"
      },
      "impact": {
        "flexibility": "Low (но неудобно)",
        "severity_score": 3
      },
      "change": {
        "description": "Move to AgentConfig в config.py",
        "implementation": "class AgentConfig: max_coding_attempts: int = 3",
        "tests": "test_config_override()",
        "breaking_changes": false
      },
      "effect": {
        "kpis": {
          "configurability": "+100%"
        },
        "measured": false
      },
      "effort_days": 0.5,
      "dependencies": [],
      "source": "improvement_plan.json:488-530"
    },
    {
      "id": "L-1",
      "title": "Implement Line Numbers для API Endpoints",
      "priority": "P4",
      "severity": "low",
      "category": "feature",
      "problem": {
        "description": "TODO: implement getting the line number для API endpoints",
        "file": "core/agents/orchestrator.py",
        "lines": [98],
        "evidence": "\"line\": 0,  # TODO"
      },
      "impact": {
        "debugging_efficiency": "Minor improvement",
        "severity_score": 2
      },
      "change": {
        "description": "Parse API route decorators via AST",
        "implementation": "AST parsing для extracting line numbers",
        "tests": "test_api_line_numbers()",
        "breaking_changes": false
      },
      "effect": {
        "kpis": {
          "debugging_efficiency": "+10%"
        },
        "measured": false
      },
      "effort_days": 1.0,
      "dependencies": [],
      "source": "improvement_plan.json:533-575"
    },
    {
      "id": "L-2",
      "title": "Implement Chat Feature",
      "priority": "P4",
      "severity": "low",
      "category": "feature",
      "problem": {
        "description": "Chat feature commented out: # self.chat = Chat() TODO",
        "file": "core/agents/orchestrator.py",
        "lines": [58],
        "evidence": "Commented code"
      },
      "impact": {
        "user_experience": "Nice-to-have",
        "severity_score": 2
      },
      "change": {
        "description": "Implement Chat class + WebSocket integration",
        "implementation": "Real-time chat via WebSocket",
        "tests": "test_chat_integration()",
        "breaking_changes": false
      },
      "effect": {
        "kpis": {
          "user_experience": "+20%"
        },
        "measured": false
      },
      "effort_days": 3.0,
      "dependencies": [],
      "source": "improvement_plan.json:576-620"
    }
  ],
  "roadmap": {
    "sprint_0_critical_blockers": {
      "duration_days": 1.0,
      "priority": "P0",
      "items": ["CR-1", "CR-2"],
      "goal": "Fix critical data integrity + reliability issues"
    },
    "sprint_1_scalability": {
      "duration_days": 11.5,
      "priority": "P1",
      "items": ["CR-3", "INFRA-1", "H-2", "H-3", "SCALE-1"],
      "goal": "Enable horizontal scaling для 10k users"
    },
    "sprint_2_security": {
      "duration_days": 8.0,
      "priority": "P2",
      "items": ["SEC-001", "SEC-002"],
      "goal": "Phase 2 security hardening (CVSS 7.5 → 4.0)"
    },
    "sprint_3_refactoring": {
      "duration_days": 11.0,
      "priority": "P2",
      "items": ["H-1", "REL-003", "CACHE-1", "OBS-1"],
      "goal": "Code quality + performance + observability"
    },
    "backlog": {
      "priority": "P3_P4",
      "items": ["M-1", "M-4", "L-1", "L-2"],
      "goal": "Nice-to-have improvements"
    }
  },
  "summary": {
    "total_items": 18,
    "total_effort_days": 42.5,
    "critical_path_days": 1.0,
    "scalability_path_days": 11.5,
    "security_path_days": 8.0,
    "quality_path_days": 11.0,
    "confidence": "high",
    "based_on": "Autonomous deep audit (10k LOC analyzed) + existing improvement_plan.json",
    "risk_level": "medium_managed"
  }
}
